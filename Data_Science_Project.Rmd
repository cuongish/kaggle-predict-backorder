---
title: "Backorders Prediction"
author: 
date:
output: html_document
---

```{r setup , include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Set input folder and working directory

```{r}
inputfolder <- "/Users/traanh/Downloads/predict-bo-trial"
setwd(inputfolder)

```

Install Packages

```{r}
#install.packages("randomForest")
#install.packages("caret")
#install.packages("pROC")
#install.packages("ROSE")
#install.packages("knitr")
#install.packages("magrittr")
#install.packages("gridExtra")
#install.packages("GGally")
#install.packages("rpart.plot")
```
## Preparing Libraries
```{r}
library(dplyr)
library(ggplot2)
library(grid)
library(gridExtra)
library(DT)
library(GGally)
library(randomForest)
library(rpart)
library(caret)
library(pROC)
library(ROSE)
library(magrittr)
library(tidyr)
library(rpart.plot)
library(tibble)
library(ROCR)
library(purrr)

```
## Loading the data 
Loading both training and testing datasets

```{r retrieve data, code_folding=show}
raw_train <- read.csv(paste(inputfolder, "Kaggle_Training_Dataset_v2.csv",sep="/"), stringsAsFactors = FALSE)
raw_test <- read.csv(paste(inputfolder, "Kaggle_Test_Dataset_v2.csv",sep="/"), stringsAsFactors = FALSE)

```

# 1. Data Inspection
## 1.1 Descriptive Analysis 
```{r}
# Examine the training dataset
str(raw_train)
head(raw_train)
raw_train$went_on_backorder %>% table() %>% prop.table()

# Examine the testing dataset
str(raw_test)
head(raw_test)
raw_test$went_on_backorder %>% table() %>% prop.table()

glimpse(raw_train)
```

Both training and testing datasets have missing values (*NA*) mainly in `lead_time` variable and outliers with the values = -99 in `perf_6_month_avg` and `perf_12_month_avg` variables 
Both training and testing datasets are severely imbalanced
 
## 1.2 Data Visualization


```{r}
qplot( as.factor(raw_train$went_on_backorder) ) + 
    geom_bar() + 
    labs(x="went_on_backorder", y="Count")

```
```{r}

raw_train %>% gather(- went_on_backorder, key = "went_on_backorder",value = "value") %>% ggplot(aes(x = value , y =went_on_backorder)) + geom_point() + facet_wrap(~ went_on_backorder, scales = "free") + theme_bw()

```




 
# 2. Data Cleaning 


## 2.1. Rebalance the datasets

We use `ROSE` library to balance the datasets
https://www.analyticsvidhya.com/blog/2016/03/practical-guide-deal-imbalanced-classification-problems/

```{r}

train_balanced<- ovun.sample(went_on_backorder~., data=raw_train, N=nrow(raw_train), p=0.5, seed=1, method="both")$data 

test_balanced <- ovun.sample(went_on_backorder~., data=raw_test,N=nrow(raw_test), p=0.5, seed=1, method="both")$data

table(train_balanced$went_on_backorder)

```
```{r}


train_balanced_under <- ovun.sample(went_on_backorder ~ ., data = raw_train, method = "under", N = 20000, seed = 1)$data

test_balanced_under <- ovun.sample(went_on_backorder ~ ., data = raw_test, method = "under", N = 5000, seed = 1 )$data

table(train_balanced_under$went_on_backorder)
```

```{r}
qplot( as.factor(train_balanced$went_on_backorder) ) + 
    geom_bar() + 
    labs(x="went_on_backorder", y="Count")
```
## 2.2. Validation Set 80-20 
We create a validation set from the training data with the random split of 80-20. The validation set would be used for building models.
```{r}

```

```{r construct training and validation sets}

n <- nrow(train_balanced)
n_train <- round(0.8 * n) 
seed <- 1234567
set.seed(seed)
train_indices <- sample(1:n, n_train)

raw_train_80 <- train_balanced[train_indices, ]  
raw_val_20 <- train_balanced[-train_indices, ]  

```
## 2.3. Data-Preprocessing 

Next we will clean the datasets by :
  * Dropping unnecessary columns 
  * Handling missing values (*NA*)
  * Deleting ouliers

```{r}

# Creating a customized function to clean data : drop `sku` column, eliminate NA and ouliers(-99)
preprocess_raw_data <- function(data) {
    # data = data frame of backorder data
    data[data == -99] <- NA
    data %>%
        select(-sku) %>%
        drop_na() %>%
        mutate_if(is.character, .funs = function(x) ifelse(x == "Yes", 1, 0)) %>%
        mutate(went_on_backorder = as.factor(went_on_backorder))
}

# Applying the function created above to these raw datasets : training, testing and validation

clean_train_80 <- preprocess_raw_data(raw_train_80) 
clean_test <- preprocess_raw_data(raw_val_20)
clean_val_20 <- preprocess_raw_data(test_balanced)
clean_train <- preprocess_raw_data(train_balanced)

clean_train_under <- preprocess_raw_data(train_balanced_under)

#Checking whether all datasets are clean and balanced 

glimpse(clean_train_80)
summary(clean_train_80)
table(clean_train_80$went_on_backorder)
any(is.na(clean_train_80))
any(is.na(clean_test))
any(is.na(clean_val_20))



```
# 3. Data Visualization

```{r}


qplot( as.factor(raw_train$went_on_backorder) ) + 
    geom_bar() + 
    labs(x="went_on_backorder", y="Count")


clean_test %>% gather(- went_on_backorder, key = "went_on_backorder",value = "value") %>% ggplot(aes(x = value , y =went_on_backorder)) + geom_point() + facet_wrap(~ went_on_backorder, scales = "free") + theme_bw()

```



```{r}
write.csv(clean_train_80, "clean_train_80.csv")
write.csv(clean_test, "clean_test.csv")
```


# 4. Modeling

## 4.1 Simple Decision-Tree model 

Next we build decision tree model from clean and balanced training dataset

```{r}


sim_tree <- rpart(formula = went_on_backorder ~ . , 
                  data = clean_train_80, 
                  method = "class",
                  parms = list(split='information'), 
                  control = rpart.control(maxdepth = 3, cp = 0 ))

rpart.plot(sim_tree)

```
### 4.1.1. Predict using the simple decision-tree model

```{r confusion matrix for the basic model}

# Generate predicted classes using the model object
class_prediction <- predict(sim_tree, clean_test, type = "class")  
                            
# Calculate the confusion matrix for the test set
confusionMatrix(class_prediction, clean_test$went_on_backorder)

```

### 4.1.2. ROC curves 
```{r}

roc_sim <- plot.roc(clean_test$went_on_backorder, predict(sim_tree, type = "prob", newdata = clean_test)[, 2], main="Confidence intervals", percent=TRUE, ci=TRUE, print.auc=TRUE) 

# CI of sensitivity
ci <- ci.se(roc_sim, specificities=seq(0, 100, 5)) # over a select set of specificities
plot(ci, type="shape", col="#1c61b6AA") # plot as a blue shape
plot(ci(roc_sim, of="thresholds", thresholds="best")) # add one threshold
```
## 4.2 Random Forest

```{r}
# Create model with default paramters

control <- trainControl(method="repeatedcv", number=10, repeats=3)
set.seed(seed)
metric <- "Accuracy"

# Using naive rule to fix the mtry parameter
mtry <- sqrt(ncol(clean_train_under) - 3)

tunegrid <- expand.grid(.mtry=mtry)
rf_default <- train(went_on_backorder ~ . , data=clean_train_under, method="rf", metric=metric, tuneGrid=tunegrid, trControl=control)
print(rf_default)

pred = predict(rf_default, newdata = test_balanced)
confusionMatrix(data = pred, reference = test_balanced$went_on_backorder, positive = "Yes")  

rocobj <- plot.roc(test_balanced$went_on_backorder, predict(rf_default, type = "prob", newdata = test_balanced)[, 2], main="Confidence intervals", percent=TRUE, ci=TRUE, print.auc=TRUE) 

# CI of sensitivity
ciobj <- ci.se(rocobj, specificities=seq(0, 100, 5)) # over a select set of specificities
plot(ciobj, type="shape", col="#1c61b6AA") # plot as a blue shape
plot(ci(rocobj, of="thresholds", thresholds="best")) # add one threshold

```

```{r}
set.seed(123)
rf <- randomForest(went_on_backorder ~ . , data = clean_train_under)
print(rf)

```

```{r}
pred = predict(rf , newdata = clean_test)
confusionMatrix(data = pred, reference = clean_test$went_on_backorder)  

rocobj <- plot.roc(clean_test$went_on_backorder, predict(rf, type = "prob", newdata = clean_test)[, 2], main="Confidence intervals", percent=TRUE, ci=TRUE, print.auc=TRUE) 

# CI of sensitivity
ciobj <- ci.se(rocobj, specificities=seq(0, 100, 5)) # over a select set of specificities
plot(ciobj, type="shape", col="#1c61b6AA") # plot as a blue shape
plot(ci(rocobj, of="thresholds", thresholds="best")) # add one threshold
```


## 4.3 Logistic Regression


```{r}



lr_model <- glm(went_on_backorder~. -potential_issue -pieces_past_due -deck_risk -oe_constraint -ppap_risk -stop_auto_buy -rev_stop,family=binomial(link='logit'),data= clean_train_under)


```



